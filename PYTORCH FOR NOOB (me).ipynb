{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "e05616e2",
   "metadata": {},
   "source": [
    "# IMPORTS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c480dd3c",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "!pip install pycm livelossplot\n",
    "%pylab inline\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from livelossplot import PlotLosses\n",
    "from pycm import *\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.datasets\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "from torchsummary import summary\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import random"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4f3e09e6",
   "metadata": {},
   "source": [
    "### Setting the seed and setting up cuda/gpu"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "711c66f2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  ## uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = False\n",
    "\n",
    "    return True\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ca4520ad",
   "metadata": {},
   "source": [
    "## CUSTOM DATASET"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2525f74b",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "class ChestMNIST(Dataset):\n",
    "    def __init__(self, data_path, split=\"train\", p=0.2, transform=None):\n",
    "        self.data_path = data_path\n",
    "        self.split = split\n",
    "        self.p = p\n",
    "        self.transform = transform\n",
    "        if self.split == \"train\":\n",
    "            self.data = np.load(self.data_path)[\"train_images\"]        \n",
    "        elif self.split == \"test\":\n",
    "            self.data = np.load(self.data_path)[\"test_images\"]        \n",
    "        elif self.split == \"val\":\n",
    "            self.data = np.load(self.data_path)[\"val_images\"]\n",
    "        else:\n",
    "            return ValueError(\"wrong split\")\n",
    "            \n",
    "    def _get_mask(self, img_shape):\n",
    "        # Create a method for your class _get_mask, that generates a binary mask\n",
    "        # of the size of the sample to randomly erase some data points based on\n",
    "        # the probability p\n",
    "\n",
    "        mask = np.random.uniform(0, 1, size=(img_shape)) > self.p\n",
    "        return mask\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample = self.data[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        # masked image (want to pred), actual image (our target)\n",
    "        return sample * self._get_mask(sample.shape), sample\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.data.shape[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "71e111b4",
   "metadata": {},
   "source": [
    "## get a validation set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0167bffa",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(mnist_train.data, mnist_train.targets)\n",
    "# gives you n, n-1 random ids that correspond to test and train subsets\n",
    "# n is the train proportion \n",
    "train_idxs, valid_idxs = [(train_idx, valid_idx) for train_idx, valid_idx in shuffler][0]\n",
    "\n",
    "X_train, y_train = mnist_train.data[train_idxs], mnist_train.targets[train_idxs]\n",
    "X_val, y_val =     mnist_train.data[valid_idxs], mnist_train.targets[valid_idxs]\n",
    "X_test, y_test =   mnist_test.data, mnist_test.targets\n",
    "\n",
    "# NOTE torch categorical data = .long()\n",
    "mnist_train =    TensorDataset(X_train, y_train.long())\n",
    "mnist_validate = TensorDataset(X_val, y_val.long())\n",
    "mnist_test =     TensorDataset(X_test, y_test.long())\n",
    "\n",
    "# from sklearn.model_selection import StratifiedShuffleSplit\n",
    "# shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(mnist_train.data, mnist_train.targets)\n",
    "# # gives you n, n-1 random ids that correspond to test and train subsets\n",
    "# # n is the train proportion \n",
    "# train_idxs, valid_idxs = [(train_idx, valid_idx) for train_idx, valid_idx in shuffler][0]\n",
    "# X_train, y_train = apply_standardization(mnist_train.data[train_idxs].float()), mnist_train.targets[train_idxs]\n",
    "# X_val, y_val =     apply_standardization(mnist_train.data[valid_idxs].float()), mnist_train.targets[valid_idxs]\n",
    "# X_test, y_test =   apply_standardization(mnist_test.data.float()), mnist_test.targets\n",
    "# mnist_train =    TensorDataset(X_train, y_train.long())\n",
    "# mnist_validate = TensorDataset(X_val, y_val.long())\n",
    "# mnist_test =     TensorDataset(X_test, y_test.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ebda16",
   "metadata": {},
   "source": [
    "# Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "577c8510",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_transform = Compose([\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.1307], std=[0.3081]),\n",
    "])\n",
    "\n",
    "validation_test_transform = Compose([\n",
    "    Normalize(mean=[0.1307], std=[0.3081])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b832156",
   "metadata": {},
   "source": [
    "### Conf matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "899ec1df",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import ConfusionMatrixDisplay\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(6,6))\n",
    "ConfusionMatrixDisplay.from_predictions(y_gt, y_pred, ax=ax, colorbar=False, cmap='bone_r')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f4bca5b1",
   "metadata": {},
   "source": [
    "# DATALOADERS (AND GETTING TORCH DATASETS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca376994",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "#\n",
    "\n",
    "# train_dataset = ChestMNIST(\n",
    "#     data_path=\"./chestmnist.npz\",\n",
    "#     split=\"train\",\n",
    "#     p=mask_probability,\n",
    "#     transform=transformations\n",
    "# )\n",
    "#\n",
    "# val_dataset = ChestMNIST(\n",
    "#     data_path=\"./chestmnist.npz\",\n",
    "#     split=\"val\",\n",
    "#     p=mask_probability,\n",
    "#     transform=transformations\n",
    "# )\n",
    "#\n",
    "# test_dataset = ChestMNIST(\n",
    "#     data_path=\"./chestmnist.npz\",\n",
    "#     split=\"test\",\n",
    "#     p=mask_probability,\n",
    "#     transform=transformations\n",
    "# )\n",
    "\n",
    "# datasets will be torch tensors eg torch.TensorDataset(X, y) X=SampleInput, y=SampleLabel\n",
    "\n",
    "train_loader = torch.utils.data.DataLoader(\n",
    "    train_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "val_loader = torch.utils.data.DataLoader(\n",
    "    val_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)\n",
    "\n",
    "test_loader = torch.utils.data.DataLoader(\n",
    "    test_dataset,\n",
    "    batch_size=batch_size,\n",
    "    shuffle=True,\n",
    "    pin_memory=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "305e707e",
   "metadata": {},
   "source": [
    "# AN EXAMPLE NEURAL NETWORK IMPLEMENTATION"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea929b8",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \n",
    "dimensions = [784, 150, 50, 50, 150, 784]\n",
    "\n",
    "class neural_net(nn.Module):\n",
    "    def __init__(self, dimensions):\n",
    "        super(neural_net, self).__init__()\n",
    "        # fully connected\n",
    "        self.fc1 = nn.Linear(dimensions[0], dimensions[1], bias=False)\n",
    "        self.fc2 = nn.Linear(dimensions[1], dimensions[2], bias=False)\n",
    "        self.fc3 = nn.Linear(dimensions[2], dimensions[3], bias=False)\n",
    "        self.fc4 = nn.Linear(dimensions[3], dimensions[4], bias=False)\n",
    "        self.fc5 = nn.Linear(dimensions[4], dimensions[-1], bias=False)\n",
    "        # activation functions/special\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "        self.tanh = nn.Tanh()\n",
    "        self.mish = nn.Mish()\n",
    "        self.relu = nn.ReLU()\n",
    "        self.softmax = nn.Softmax()\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "\n",
    "    def forward(self, X):\n",
    "        # INPUT LAYER\n",
    "        out = self.fc1(X.flatten(start_dim=1).float())\n",
    "        out = self.mish(out)\n",
    "        \n",
    "        # HIDDEN 1\n",
    "        out = self.fc2(out)\n",
    "        out = self.mish(out)\n",
    "        \n",
    "        # HIDDEN 2\n",
    "        out = self.fc3(out)\n",
    "        out = self.mish(out)\n",
    "\n",
    "        # HIDDEN 3\n",
    "        out = self.fc4(out)\n",
    "        out = self.mish(out)\n",
    "        \n",
    "        # OUTPUT LAYER\n",
    "        out = self.fc5(out)\n",
    "        out = self.sigmoid(out)\n",
    "\n",
    "        # TRANSFORMED OUTPUT LAYER \n",
    "        return out.view(X.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a8a373f0",
   "metadata": {},
   "source": [
    "# CHECKING A BATCH (+ OPT/LOSS FUNCS)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7cb0e695",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "#~ CHECKING EVERYTHING FITS CELL\n",
    "\n",
    "# get a batch\n",
    "train_batch = next(iter(train_loader))\n",
    "\n",
    "X = torch.Tensor(train_batch[0])\n",
    "y = torch.Tensor(train_batch[1])\n",
    "\n",
    "print(f\"X.shape = {X.shape}\")\n",
    "print(f\"y.shape = {y.shape}\")\n",
    "\n",
    "# ensure prediction works\n",
    "model = neural_network()\n",
    "output = model(X)\n",
    "\n",
    "print(f\"  OUTPUT SHAPE: {output.shape} (pre-softmax)\")\n",
    "print(f\"EXPECTED SHAPE: {y.shape}\")\n",
    "\n",
    "# ensure loss works\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "print(criterion(output, y))\n",
    "\n",
    "# --\n",
    "optimizer = torch.optim.Adam(model.parameters(), weight_decay=weight_decay, lr=learning_rate)   # instantiate the optimizer\n",
    "criterion = nn.MSELoss()\n",
    "\n",
    "# # get a batch\n",
    "# train_batch = next(iter(train_loader))\n",
    "\n",
    "# # masked images\n",
    "# X = torch.Tensor(train_batch[0]).reshape(-1,1,28,28)\n",
    "# # unmasked images\n",
    "# y = torch.Tensor(train_batch[1].float())\n",
    "\n",
    "# print(f\"X.shape = {X.shape}\")\n",
    "# print(f\"y.shape = {y.shape}\")\n",
    "# # ensure prediction works\n",
    "# model = LeNet5drbn()\n",
    "# output = model(X)\n",
    "\n",
    "# print(f\"  OUTPUT SHAPE: {output.shape}\")\n",
    "# print(f\"EXPECTED SHAPE: {y.shape}\")\n",
    "\n",
    "# # ensure loss works\n",
    "# criterion = nn.CrossEntropyLoss()\n",
    "# y = y.long()\n",
    "# print(criterion(output, y))\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cfe00c56",
   "metadata": {},
   "source": [
    "# TRAIN, VALIDATE, EVALUATE FUNCTIONS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "502ef069",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "# \n",
    "\n",
    "def train(model, optimizer, criterion, data_loader):\n",
    "    model.train()##\n",
    "    ### set the model to train\n",
    "    model.to(device)\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for X, y in data_loader:\n",
    "        \n",
    "        X, y = X.to(device), y.to(device)\n",
    "#         print(X.view(-1, 1, 28, 28).shape)\n",
    "#         X = X.view(-1, 1, 28, 28)\n",
    "#         outputs = model(X)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(X.view(-1, 1, 28, 28))\n",
    "        \n",
    "        loss = criterion(outputs, y)\n",
    "        loss.backward()##\n",
    "        train_loss += loss*y.size(0)\n",
    "        y_pred = F.log_softmax(outputs, dim=1).max(1)[1]##\n",
    "        train_accuracy += accuracy_score(\n",
    "            y.cpu().numpy(), \n",
    "            y_pred.detach().cpu().numpy())*X.size(0) ##\n",
    "\n",
    "        optimizer.step()\n",
    "        ### your code goes here\n",
    "    \n",
    "    # loss, acc\n",
    "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
    "\n",
    "\n",
    "def validate(model, criterion, data_loader):\n",
    "    ### set the model to evaluate\n",
    "    validation_loss, validation_accuracy = 0, 0\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X.view(-1, 1, 28, 28))\n",
    "            loss = criterion(outputs, y)\n",
    "            validation_loss += loss*y.size(0)\n",
    "            y_pred = F.log_softmax(outputs, dim=1).max(1)[1]##\n",
    "            validation_accuracy += accuracy_score(\n",
    "                y.cpu().numpy(), \n",
    "                y_pred.detach().cpu().numpy())*X.size(0) ##\n",
    "\n",
    "            \n",
    "\n",
    "\n",
    "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
    "\n",
    "\n",
    "def evaluate(model, data_loader):\n",
    "    ### set the model to evaluate\n",
    "    ys, y_preds = [], []\n",
    "    model.to(device)\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            outputs = model(X.view(-1, 1, 28, 28))\n",
    "            y_pred = F.log_softmax(outputs, dim=1).max(1)[1]\n",
    "            y_preds.append(y_pred.cpu().numpy())\n",
    "            ys.append(y.cpu().numpy())\n",
    "\n",
    "\n",
    "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c02052cd",
   "metadata": {},
   "source": [
    "# TRAINING LOOP (Live plotting)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a7774778",
   "metadata": {
    "code_folding": [
     0
    ]
   },
   "outputs": [],
   "source": [
    "def train_model(model, model_params=None):\n",
    "    set_seed(seed)\n",
    "    model = model(model).to(device)\n",
    "\n",
    "    optimizer = optimizer = torch.optim.Adam(model.parameters(), lr=lr,momentum=momentum)\n",
    "    criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "    train_loader = DataLoader(\n",
    "        mnist_train,\n",
    "        batch_size=batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=False, \n",
    "        num_workers=0,)\n",
    "    \n",
    "    validation_loader = DataLoader(\n",
    "        mnist_validate,\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=False, \n",
    "        num_workers=0,)\n",
    "    \n",
    "    test_loader = DataLoader(\n",
    "        mnist_test,\n",
    "        batch_size=test_batch_size,\n",
    "        shuffle=True,\n",
    "        pin_memory=False, \n",
    "        num_workers=0,)\n",
    "\n",
    "    liveloss = PlotLosses()\n",
    "    for epoch in range(30):\n",
    "        logs = {}\n",
    "        train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "\n",
    "        logs['' + 'log loss'] = train_loss.item()\n",
    "        logs['' + 'accuracy'] = train_accuracy.item()\n",
    "\n",
    "        validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
    "        logs['val_' + 'log loss'] = validation_loss.item()\n",
    "        logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
    "\n",
    "        liveloss.update(logs)\n",
    "        liveloss.draw()\n",
    "\n",
    "    return model\n",
    "\n",
    "model = train_model(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "90790235",
   "metadata": {},
   "source": [
    "## Other stuff :/"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "409b76a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "### Saving a model\n",
    "# model_save_name = \n",
    "path = f\"/content/gdrive/My Drive/models/{model_save_name}\"\n",
    "torch.save(model.state_dict(), path)\n",
    "\n",
    "### Loading a model"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
